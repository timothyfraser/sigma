# Multivariate Regression: Modeling Effects of Disaster on Social Capital

```{r setup_workshop_12, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE, message = FALSE, warning = FALSE)

library(tidyverse)
library(rmdformats)
library(knitr)
library(broom)
library(moderndive)
library(gganimate)
library(gifski)
library(magick)
```

```{r, message = FALSE, warning = FALSE, echo = FALSE}
read_csv("workshops/japan_muni_elections.csv") %>%
  filter(year >= 2011) %>%
  filter(by_tsunami != "Other") %>%
  mutate(year = factor(year)) %>%
  mutate(by_tsunami = factor(by_tsunami, levels = c("Not Hit", "Hit"))) %>%
  # Exclude anyone in the exclusion zone,
  # because these places have no population after 2011,
  # and aren't really comparable
  filter(exclusion_zone == 0) %>%
  # Filter out edogawa-ku in Tokyo,
  # because it's *definitely* not comparable
  filter(pref != "Tokyo") %>%
  mutate(income_per_capita = income_thous_per_capita / 1000) %>%
  mutate(damage_rate = damage_rate / 1000) %>%
  select(muni_code, muni, pref, year, by_tsunami, 
         social_capital, 
         damage_rate,
         pop_density,
         exp_dis_relief_per_capita,
         income_per_capita,
         unemployment, 
         pop_women,
         pop_over_age_65) %>%
  # Round social capital to 3 digits
  mutate(social_capital = round(social_capital, 3)) %>%
  mutate(pop_density = round(pop_density, 3)) %>%
  mutate(exp_dis_relief_per_capita = round(exp_dis_relief_per_capita, 2)) %>%
  mutate(income_per_capita = round(income_per_capita, 2)) %>%
  mutate(unemployment = round(unemployment, 2)) %>%
  mutate(pop_women = round(pop_women, 1)) %>%
  mutate(pop_over_age_65 = round(pop_over_age_65, 1)) %>%
  mutate(damage_rate = round(damage_rate, 3)) %>%
  write_csv("workshops/jp_matching_experiment.csv")
```


```{r, message= FALSE, warning = FALSE, fig.width=10, fig.height=10, echo = FALSE}
knitr::include_graphics(path = "images/myplot.png")
```

Why do some communities see stronger **social capital** than others? **Social capital** refers to the social ties that bind results, enabling trust and collective action among residents to tackle public issues. [Recent studies suggest](https://doi.org/10.1016/j.ijdrr.2018.11.009) that after disasters, residents' social capital actually increases, because people recognize the value of friends and family as they work to recover and rebuild. We can use regression analysis to test this hypothesis on new data!

This workshop examines 151 Japanese municipalities over 7 years, from 2011 to 2017 (`jp_matching_experiment.csv`), totaling 1057 city-year observations. This includes 85 coastal municipalities hit by the 2011 tsunami and 66 municipalities as similar as possible, just next door, that were not hit. Let's load in our data and get started.

<br>

##  Getting Started {-}

### Load Data & Packages {-}

In this dataset, each row is a city-year!

```{r, message = FALSE, warning = FALSE}
# Load Packages
library(tidyverse) # for data manipulation
library(broom) # for each model summaries
library(texreg) # for nice model tables

# Load Data
cities <- read_csv("workshops/jp_matching_experiment.csv") %>%
  # Tell R to treat year and pref as ordered categories
  mutate(year = factor(year),
         pref = factor(pref))
```

### View Data {-}

```{r, eval = FALSE}
# View first 3 rows of dataset
cities %>% head(3)
```

```{r, echo = FALSE}
cities %>% head(3) %>% kable()
```

### Codebook {-}

In this dataset, our variables mean:


- `muni_code` unique 5 digit idenfier for each municipality.

- `muni`: municipality where election took place

- `pref`: prefecture that municipality is in

- `year`: year of observation.

- `by_tsunami`: was that city struck by the tsunami ("Hit"), not hit but just next door ("Not Hit"), or some other municipality ("Other")?

**Outcome Variable**

- `social_capital`: index measuring overall social capital, the social ties between residents that build trust, using several dimensions. Measured on a scale from 0 (low) to 1 (high).

**Explanatory Variable**

- `damage_rate`: rate of buildings damaged or destroyed by earthquake and tsunami, per million residents.

**Control Variables**

- `exp_dis_relief_per_capita`: spending on disaster relief in 1000s of yen per capita.

- `income_per_capita`: income per capita in millions of yen per capita.

- `unemployment`: unemployment rate per 1,000 residents.

- `pop_women`: % residents who are women

- `pop_over_age_65`: % residents over age 65

- `pop_density`: population in 1000s of residents per square kilometer


<br>
<br>

##  Multiple Regression

### Beta coefficients

We can use a regression model to test the association between our **outcome variable** `social_capital` and our **explanatory variable** `by_tsunami`. Using the `lm()` function, we can get a **beta** coefficient estimating how much higher a social capital index score they received for every additional building damaged per million residents.

```{r, message = FALSE, warning = FALSE}
cities %>%
  lm(formula = social_capital ~ damage_rate)
```

<br>
<br>

### Controls

But... many other things might affect social capital in a community, not just getting hit by the tsunami: For example, (1) population density, (2) wealth, (3) unemployment, (4) age, (5) government capacity, (6) disaster relief, (7) time, and even (8) regional differences. We need to add **control variables** to our model to **control** for these alternative explanations for variation in social capital. This will **refine** our beta coefficient for the effect of the tsunami, getting us closer to the truth.

We can add extra control variables using `+` in the `lm()` function. For example, we test the effect of `damage_rate` below, controlling for `income_per_capita`.

```{r, message = FALSE, warning = FALSE}
cities %>%
  lm(formula = social_capital ~ damage_rate + income_per_capita)
```

```{r, message = FALSE, warning = FALSE, echo = FALSE}
myresult <- cities %>%
  lm(formula = social_capital ~ damage_rate + income_per_capita)
```


Our model tells us that for every building damaged per million residents, the social capital index increased by `r myresult$coefficient[2] %>% round(2)`. For every additional million yen per capita in income, the average city's social capital index increased by `r myresult$coefficient[3] %>% round(2)`.


<br>
<br>

### Planes

Instead of a line of best fit, for 2 variables, this regression model now essentially predicts a plane of best fit for 3 variables. See below. And, given 4 or more variables, a regression model will predict a hyperplane of best fit. Not easy to visualize, but just think: 4 variables means 4 dimensions. 5 variables means 5 dimensions. 

```{r, fig.width = 8, fig.height=8, echo = FALSE, warning = FALSE, message = FALSE}
library(plot3D)
# Get color scheme
mycolors = viridis::viridis(n = 3, option = "mako", begin = 0.9, end = 0.3)

# x, y, z variables
x <- cities$income_per_capita
#y <- if_else(cities$by_tsunami == "Hit", 1, 0)
y <- cities$damage_rate
z <- cities$social_capital
# Compute the linear regression (z = ax + by + d)
fit <- lm(z ~ x + y)
# predict values on regular xy grid
grid.lines = 20
x.pred <- seq(min(x), max(x), length.out = grid.lines)
y.pred <- seq(min(y), max(y), length.out = grid.lines)
xy <- expand.grid( x = x.pred, y = y.pred)
z.pred <- matrix(predict(fit, newdata = xy), 
                 nrow = grid.lines, ncol = grid.lines)
# fitted points for droplines to surface
fitpoints <- predict(fit)


scatter3D(x, y, z, 
          cex.main = 2, cex.lab = 2, cex.axis = 1.5,
          ticktype= "detailed",
          type = "p",  phi = 0,
          col.grid = "darkgrey", col.panel = "black", bty = "u",
          col = ramp.col(mycolors),colkey = FALSE,
          pch = 21, bg = "white",
          surf = list(x = x.pred, 
                      y = y.pred, 
                      z = z.pred,
                      facets=T, border= "white", lwd = 0.2,
                      alpha = 0.75),
          clab = "Social\nCapital",
          xlab = "\n\nIncome per capita\n(millions of yen)",
          ylab = "\n\nDamage Rate\n(per million people)",
          zlab = "\n\nSocial Capital",
          main = paste("Social Capital~",
                       round(fit$coefficients[1], 3), " + ", round(fit$coefficients[3], 3), " x Damage",
                       "\n+ ", round(fit$coefficients[2], 4), " x Income", sep = ""))
```

<br>
<br>
<br>
<br>


---

## Learning Check 1 {.unnumbered .LC}

**Question**


<text style="color:#9F2042">Make a regression model testing the effect of a city's `damage_rate` on `social_capital`, controlling for `pop_density`. What's the effect of `damage_rate` on `social_capital`?

<br>
<br>

<details><summary>**[View Answer!]**</summary>

```{r, message = FALSE, warning = FALSE}
cities %>%
  lm(formula = social_capital ~ damage_rate + pop_density)
```

```{r, message = FALSE, warning = FALSE, echo = FALSE}
myresult2 <- cities %>%
  lm(formula = social_capital ~ damage_rate + pop_density)
```

Controlling for population density, as damage rates increase by 1 building per million residents, the social capital index increases by `r myresult2$coefficients[2] %>% round(3)` points.

</details>

---

<br>
<br>
<br>


##  Effect Sizes

One big challenge with multiple regression is that it's not really clear how to compare the size of our beta coefficients. Is 1 damaged building per million residents greater than or less than 1 square kilometer per 1000 residents, or 1 million yen per capita? To compare the size of our beta coefficients, our variables must have the same *units.* We can do this by turning our numeric variables into Z-scores.

Remember that a Z-score is a measure of *how many standard deviations from the mean a specific value is for a given variable.* We can ```mutate()``` variables into Z-scores using the ```scale()``` function.

```{r, message = FALSE, warning = FALSE}
rescaled <- cities %>%
  # For each numeric variable, rescale its values
  mutate(social_capital = scale(social_capital),
         damage_rate = scale(damage_rate),
         pop_density = scale(pop_density),
         exp_dis_relief_per_capita = scale(exp_dis_relief_per_capita),
         income_per_capita = scale(income_per_capita),
         unemployment = scale(unemployment),
         pop_women = scale(pop_women),
         pop_over_age_65 = scale(pop_over_age_65))
```

Check out our new rescaled variables.

```{r, message = FALSE, warning = FALSE, eval = FALSE}
rescaled %>% head(3)
```

```{r, message = FALSE, warning = FALSE, echo = FALSE}
rescaled %>% head(3) %>% kable()
```

Okay, let's repeat our model, this time using our new data.frame `rescaled`, and save the model as `m0`.

```{r, message = FALSE, warning = FALSE}
m0 <- rescaled %>%
  lm(formula = social_capital ~ damage_rate + pop_density)
# View model
m0
```


We can now interpret our results as: As the damage rate increases by 1 standard deviation (*new unit of predictor*), the social capital index increases by **`r round(m0$coefficient[2], 2)` standard deviations** (*new unit of outcome*), controlling for population density.

<br>
<br>

---

## Learning Check 2 {.unnumbered .LC}

**Question**

<text style="color:#9F2042">Make a second regression model called `m1`, that *also* controls for the effect of `year`. Because we made it a `factor()`, we control for each year. The `beta` coefficient tells us now *how many more standard deviations of social capital* we got in year X compared to the first year (2011), our baseline for comparison. The `alpha` coefficient tells us how many standard deviations we got during the our baseline year. Which year had the largest effect on social capital, and how much was that effect?

<details><summary>**[View Answer!]**</summary>

```{r, message = FALSE, warning = FALSE}
m1 <- cities %>%
  lm(formula = social_capital ~ damage_rate + pop_density + year)
# View model
m1
```

```{r, message = FALSE, warning = FALSE, echo = FALSE}
b2017 <- round(m1$coefficients[9], 4)

a2011 <- round(m1$coefficients[1], 4)
```

2017 had the largest effect on social capital, compared to 2011. In 2011, the average city saw `r a2011` standard deviations above the mean of social capital. In 2017, the average city saw `r b2017` standard deviation more social capital than in 2011 (totaling `r b2017 + a2011` standard deviation above the mean).

Notice that we didn't rescale categorical variables. In regression, categorical variables can't be rescaled or compared to numeric variables.

</details>

---

<br>
<br>
<br>
<br>

## Multiple Models

To find the best model, it helps to make several, in a logical, systematic way. 

- Choose your explanatory variable whose effect you really want to test. For us, that's disaster damage (`damage_rate`). Add choose your absolutely most essential control variables, without which the model isn't very valid. For us, that's `pop_density` and `year`.  (Already done and saved as `m1`!)

```{r, message=FALSE, warning = FALSE}
# For your reference
m1 <- rescaled %>%
  lm(formula = social_capital ~ damage_rate + pop_density + year)
```

- Add more controls, to wean out effects of other phenomena and get a more accurate beta coefficient for `damage_rate`. Let's add `exp_dis_relief_per_capita`, to control for city government spending on disaster relief. Save that as `m2`.

```{r}
m2 <- rescaled %>%
  lm(formula = social_capital ~ damage_rate + pop_density + year +
       exp_dis_relief_per_capita)
```

- Examine our two tables, using the `texreg` package's `htmlreg()` function. We're going to `list()` our models `m1` and `m2`, and ask R to save a nice table in our files as `"table_1.html"`. Try it out, then go to your files in the right-hand corner and click `'View in Web Browser'`! 

```{r, eval = FALSE}
htmlreg(list(m1,m2), 
        bold = 0.05, include.fstat = TRUE, 
        file = "workshops/workshop_11_table_1.html")
```


<details><summary>**[Click to view table!]**</summary>

```{r, message = FALSE, warning = FALSE, echo = FALSE}
htmltools::includeHTML(path = "workshops/workshop_11_table_1.html")
```

</details>

Pretty nice, right? The ```bold = 0.05``` says, if your p-value is below p < 0.05, make the estimate bold in the chart, so it's easy to see. ```include.fstat = TRUE``` means, please include the F-statistic at the bottom of the chart.

<br>
<br>

---

## Learning Check 3 {.unnumbered .LC}

**Question**

<text style="color:#9F2042">Make another model called `m3`, adding as controls `income_per_capita`,  `unemployment`,  `pop_women`, and `pop_over_age_65`. Then make a model called `m4`, which adds `pref`, the prefecture each city is in (like their state). Finally, put them together in a `htmlreg()` table that visualizes `m1`, `m2`, `m3`, and `m4` side by side, called `"table_2.html"`. Look at the R-squared statistic at the bottom. Which model fits best?

<br>
<br>

<details><summary>**[View Answer!]**</summary>

Adding controls `income_per_capita`,  `unemployment`,  `pop_women`, and `pop_over_age_65`...

```{r, message = FALSE, warning = FALSE}
m3 <- rescaled %>%
  lm(formula = social_capital ~ damage_rate + pop_density + year +
       exp_dis_relief_per_capita +
       income_per_capita + unemployment +  pop_women + pop_over_age_65)
```

Adding prefectural controls...

```{r, message = FALSE, warning = FALSE}
m4 <- rescaled %>%
  lm(formula = social_capital ~ damage_rate + year + pop_density + 
       exp_dis_relief_per_capita +
       income_per_capita + unemployment + pop_women + pop_over_age_65 +
       pref)
```

Making a nice table!

```{r, message = FALSE, warning = FALSE}
htmlreg(list(m1,m2,m3,m4), 
        bold = 0.05, include.fstat = TRUE, 
        file = "workshops/workshop_11_table_2.html")
```

Model 4 fits best, with an R<sup>2</sup> of 0.89. It explains 89% of the variation in social capital! That's wild! 

</details>

<details><summary>**[Click to view Table from Answer!]**</summary>

```{r, message = FALSE, warning = FALSE, echo = FALSE}
htmltools::includeHTML(path = "workshops/workshop_11_table_2.html")
```

</details>

---

<br>
<br>
<br>
<br>

## Great Tables

Finally, let's add a few bells and whistles to our model table, to make it look really nice.

<details><summary>**[Click here to learn about texreg() arguments!]**</summary>

- `custom.model.names` lets you add names for each column.

- `custom.coef.map` lets you rename variables. It also lets you rearrange them in whatever order makes sense to you. Only variables you rename will stay in the table, so it also will let us exclude the `year` effects, which are a few too numerous to report.

- `caption` adds a nice title. `caption.above = TRUE` puts it on top of the table.

- `custom.note` adds a footnote. Always indicate levels of statistical significance. 

- ```single.row = TRUE``` puts everything on one row, which is helpful.

</details>

```{r, message = FALSE, warning = FALSE, eval = FALSE}
htmlreg(
  list(m1,m2,m3,m4),
  bold = 0.05, 
  include.fstat = TRUE,
  file = "workshops/workshop_11_table_3.html",
  # Add column labels
  custom.model.names = c(
    "Basic Model", "with Controls", 
    # You can split lines in two with <br>
    "With Extended<br>Controls", 
    "With Geographic<br>Controls"),
  # Add labels
  custom.coef.map = list(
    "damage_rate" = "Damage Rate", 
    "exp_dis_relief_per_capita" = "Disaster Spending Rate",
    "income_per_capita" = "Income per capita",
    "unemployment" = "Unemployment Rate", 
    "pop_women" = "% Women", 
    "pop_over_age_65" = "% Over Age 65",
    "prefAomori" = "Aomori",
    "prefChiba" = "Chiba",
    "prefFukushima" = "Fukushima", 
    "prefIbaraki" = "Ibaraki",
    "prefIwate" = "Iwate", 
    "prefMiyagi" = "Miyagi",
    "(Intercept)" = "Intercept"),
  # Add a table caption
  caption = "OLS Model of Social Capital in Japanese Cities over 7 years",
  # You can still add a custom note too!
  custom.note = "Statistical Significance: *** p < 0.001; ** p < 0.01; * p < 0.05. Akita is the baseline prefecture. All models also control for each year (2011-2017) as a categorical variable.")
```


<details><summary>**[Click to view table!]**</summary>

```{r, message = FALSE, warning = FALSE, echo = FALSE}
htmltools::includeHTML(path = "workshops/workshop_11_table_3.html")
```

</details>

<br>
<br>

---

## Learning Check 4 {.unnumbered .LC}

**Question**

<text style="color:#9F2042">Make a new `texreg` table called `"table_4.html"`, but this time, remove the `pref` categorical effects from the table, and make a note in the custom note of in which model we controlled for prefecture. Finally, what's the effect of disaster damage in our final model? How significant is that effect?

<details><summary>**[View Answer!]**</summary>

```{r, message = FALSE, warning = FALSE, eval = FALSE}
htmlreg(
  list(m1,m2,m3,m4),
  bold = 0.05, 
  include.fstat = TRUE,
  file = "workshops/workshop_11_table_4.html",
  custom.model.names = c(
    "Basic Model", "with Controls", 
    "With Extended<br>Controls", 
    "With Geographic<br>Controls"),
  custom.coef.map = list(
    "damage_rate" = "Damage Rate", 
    "exp_dis_relief_per_capita" = "Disaster Spending Rate",
    "income_per_capita" = "Income per capita",
    "unemployment" = "Unemployment Rate", 
    "pop_women" = "% Women", 
    "pop_over_age_65" = "% Over Age 65",
    # Notice I removed the prefectures here
    "(Intercept)" = "Intercept"),
  caption = "OLS Model of Social Capital in Japanese Cities over 7 years",
  # Notice I added more to the note.
  custom.note = "Statistical Significance: *** p < 0.001; ** p < 0.01; * p < 0.05.
  All models also control for each year (2011-2017) as a categorical variable. Final model also controls for prefectures. Akita is the baseline prefecture.")
```

</details>

<br>
<br>

<details><summary>**[Click to view table from Answer!]**</summary>

```{r, message = FALSE, warning = FALSE, echo = FALSE}
htmltools::includeHTML(path = "workshops/workshop_11_table_4.html")
```


</details>

---

<br>
<br>

```{r, include = FALSE}
rm(list = ls())
```
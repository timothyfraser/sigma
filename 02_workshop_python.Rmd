# Distributions and Descriptive Statistics in Python

```{r setup_workshop_2_python, include=FALSE}
## Global options
knitr::opts_chunk$set(cache = FALSE, message = FALSE, warning = FALSE)
```

This tutorial introduces distributions and descriptive statistics in Python using pandas and helper functions that mirror `R`'s syntax.

## Getting Started {-}

### Install and Import Packages {-}

```{python, eval=FALSE}
%pip install pandas plotnine scipy
```

```{python}
import os, sys
import pandas as p
from plotnine import *
sys.path.append(os.path.abspath('functions'))
from functions_distributions import *
```

## Our Data

```{python}
sw = p.Series([4.5, 5, 5.5, 5, 5.5, 6.5, 6.5, 6, 5, 4])
sw
```

## Size

### Length

```{python}
len(sw)
```

## Location

### Mean and Median

```{python}
sw.mean()
```

```{python}
sw.median()
```

### Mode

```{python}
sw.mode()
```

## Spread (1)

### Percentiles

```{python}
sw.quantile(q=0)  # min
sw.quantile(q=1)  # max
sw.quantile(q=.75)
```

## Spread (2)

### Standard Deviation, Variance, CV, SE

```{python}
# Manual SD (sample)
x = ((sw - sw.mean())**2).sum()
x = x / (len(sw) - 1)
x**0.5
```

```{python}
sw.std()
sw.var()
sw.std()**2
sw.std() / sw.mean()  # CV
```

```{python}
se = sw.std() / (len(sw)**0.5)
se
```

## Shape

### Skewness and Kurtosis

```{python}
diff = sw - sw.mean()
n = len(sw) - 1
sigma = sw.std()
sum(diff**3) / (n * sigma**3)
sum(diff**4) / (n * sigma**4)
```

```{python}
# Using helper functions mirroring R
skewness(sw)
kurtosis(sw)
```

## Finding Parameters for Your Distributions

```{python}
sw = p.Series([4.5, 5, 5.5, 5, 5.5, 6.5, 6.5, 6, 5, 4])
mymean = sw.mean()
mysd = sw.std()
```

## Common Distributions

### Normal

```{python}
mynorm = rnorm(n=1000, mean=mymean, sd=mysd)
hist(mynorm)
```

### Poisson

```{python}
mypois = rpois(n=1000, mu=mymean)
hist(mypois)
```

### Exponential

```{python}
myrate_e = 1 / sw.mean()
myexp = rexp(n=1000, rate=myrate_e)
hist(myexp)
```

### Gamma

```{python}
myshape = sw.mean()**2 / sw.var()
myrate = 1 / (sw.var() / sw.mean())
mygamma = rgamma(n=1000, shape=myshape, rate=myrate)
hist(mygamma)
```

### Weibull

```{python}
from scipy import stats as fitdistr
myshape_w, loc, myscale_w = fitdistr.weibull_min.fit(sw, floc=0)
myweibull = rweibull(n=1000, shape=myshape_w, scale=myscale_w)
hist(myweibull)
```

## Comparing Distributions

```{python}
mysim = p.concat([
  p.DataFrame({'x': sw, 'type': "Observed"}),
  p.DataFrame({'x': mynorm, 'type': "Normal"}),
  p.DataFrame({'x': mypois, 'type': "Poisson"}),
  p.DataFrame({'x': mygamma, 'type': "Gamma"}),
  p.DataFrame({'x': myexp, 'type': "Exponential"}),
  p.DataFrame({'x': myweibull, 'type': "Weibull"})
])

g1 = (ggplot(mysim, aes(x='x', fill='type')) +
  geom_density(alpha=0.5) +
  labs(x='Seawall Height (m)', y='Density (Frequency)', subtitle='Which distribution fits best?', fill='Type'))
g1
```

```{python}
g1 + xlim(0,10)
```

---

## Learning Check 1 {.unnumbered .LC}

**Question**

Simulate 1000 draws from a normal distribution using your `sw` mean and standard deviation. What are the simulated mean and sd? How close are they to `sw`â€™s?

<details><summary>**[View Answer!]**</summary>

```{python}
mymean = sw.mean(); mysd = sw.std()
m = rnorm(1000, mean=mymean, sd=mysd)
[m.mean(), m.std()]
```

</details>

---

## Conclusion {.unnumbered}

You computed size, location, spread, and shape statistics and compared common simulated distributions using helper functions that mirror R.

```{python, include=FALSE}
globals().clear()
```

